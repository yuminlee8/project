{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35819f5-6319-4ad1-bb6a-49010ca2efd3",
   "metadata": {},
   "source": [
    "# Reddit ÎåìÍ∏Ä Í∑úÏπô ÏúÑÎ∞ò Ïó¨Î∂Ä Î∂ÑÎ•ò"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a26a6-5f7a-4c32-b05f-5ba6a35193a9",
   "metadata": {},
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2fd44f-917c-4a2c-9968-3e43706f567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3434f8-3979-4542-a2a6-30cd7d97ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSD_PATH = '/Volumes/PortableSSD'\n",
    "PROJECT_PATH = f'{SSD_PATH}/Projects/kaggle-project'\n",
    "RESULTS_PATH = f'{SSD_PATH}/Projects/results'\n",
    "MODELS_PATH = f'{SSD_PATH}/Projects/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053f2139-6740-4d2f-a201-4792ab4bffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431b09d9-7471-4ddb-9dbc-b36aa188b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c6badc-c320-4884-b839-496f7c42f7d3",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0665033d-a592-4e98-a212-3c35c94ed3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2029, 9)\n",
      "Test shape: (10, 8)\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "train_df = pd.read_csv('../data/jigsaw_agile/train.csv')\n",
    "test_df = pd.read_csv('../data/jigsaw_agile/test.csv')\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞ ÌôïÏù∏\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a549074-767f-4368-b188-7bad9da0d2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2029 entries, 0 to 2028\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   row_id              2029 non-null   int64 \n",
      " 1   body                2029 non-null   object\n",
      " 2   rule                2029 non-null   object\n",
      " 3   subreddit           2029 non-null   object\n",
      " 4   positive_example_1  2029 non-null   object\n",
      " 5   positive_example_2  2029 non-null   object\n",
      " 6   negative_example_1  2029 non-null   object\n",
      " 7   negative_example_2  2029 non-null   object\n",
      " 8   rule_violation      2029 non-null   int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 142.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82e41a43-7d9c-46d9-8741-dd42c15bf1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>If you could tell your younger self something ...</td>\n",
       "      <td>hunt for lady for jack off in neighbourhood ht...</td>\n",
       "      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n",
       "      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n",
       "      <td>LOLGA.COM is One of the First Professional Onl...</td>\n",
       "      <td>#Rapper \\nüö®Straight Outta Cross Keys SC üö®YouTu...</td>\n",
       "      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Don't break up with him or call the cops.  If ...</td>\n",
       "      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Because this statement of his is true. It isn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>Selling Tyrande codes for 3‚Ç¨ to paypal. PM. \\n...</td>\n",
       "      <td>tight pussy watch for your cock get her at thi...</td>\n",
       "      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n",
       "      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>wow!! amazing reminds me of the old days.Well...</td>\n",
       "      <td>seek for lady for sex in around http://p77.pl/...</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                               body  \\\n",
       "0       0  Banks don't want you to know this! Click here ...   \n",
       "1       1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2       2  Lol. Try appealing the ban and say you won't d...   \n",
       "3       3  she will come your home open her legs with  an...   \n",
       "4       4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "\n",
       "                                                rule      subreddit  \\\n",
       "0  No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2  No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3  No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4  No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "\n",
       "                                  positive_example_1  \\\n",
       "0  If you could tell your younger self something ...   \n",
       "1  [I wanna kiss you all over! Stunning!](http://...   \n",
       "2  Don't break up with him or call the cops.  If ...   \n",
       "3  Selling Tyrande codes for 3‚Ç¨ to paypal. PM. \\n...   \n",
       "4   wow!! amazing reminds me of the old days.Well...   \n",
       "\n",
       "                                  positive_example_2  \\\n",
       "0  hunt for lady for jack off in neighbourhood ht...   \n",
       "1  LOLGA.COM is One of the First Professional Onl...   \n",
       "2  It'll be dismissed: https://en.wikipedia.org/w...   \n",
       "3  tight pussy watch for your cock get her at thi...   \n",
       "4  seek for lady for sex in around http://p77.pl/...   \n",
       "\n",
       "                                  negative_example_1  \\\n",
       "0  Watch Golden Globe Awards 2017 Live Online in ...   \n",
       "1  #Rapper \\nüö®Straight Outta Cross Keys SC üö®YouTu...   \n",
       "2  Where is there a site that still works where y...   \n",
       "3  NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
       "4  must be watch movie https://sites.google.com/s...   \n",
       "\n",
       "                                  negative_example_2  rule_violation  \n",
       "0  DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n",
       "1  [15 Amazing Hidden Features Of Google Search Y...               0  \n",
       "2  Because this statement of his is true. It isn'...               1  \n",
       "3  Good News ::Download WhatsApp 2.16.230 APK for...               1  \n",
       "4  We're streaming Pokemon Veitnamese Crystal RIG...               1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747a6fd3-04c1-4930-a099-5acf27d70c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rule_violation\n",
       "1    1031\n",
       "0     998\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï ÌôïÏù∏\n",
    "train_df[\"rule_violation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f815b-bac9-41b9-8265-da630b32ce85",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414aedfd-b402-45a6-94bb-d11cffc97b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # ÏÜåÎ¨∏ÏûêÎ°ú ÌÜµÏùº\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # urlÏù¥ Ìè¨Ìï®Îêú Í≤ΩÏö∞ [URL] ÌÜ†ÌÅ∞ÏúºÎ°ú ÏπòÌôò\n",
    "    text = re.sub(r'http\\S+|www\\S+', '[URL]', text)\n",
    "\n",
    "    # ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞\n",
    "    text = re.sub(r'[^\\w\\s[\\]]', '', text)\n",
    "\n",
    "    # Í≥µÎ∞± Ï†úÍ±∞\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815aae5e-c67f-40d8-aef2-4754f23a8b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data sample: banks dont want you to know this click here to know more [RULE] no advertising spam referral links u\n"
     ]
    }
   ],
   "source": [
    "body_processed = train_df[\"body\"].apply(preprocess_text)\n",
    "rule_processed = train_df[\"rule\"].apply(preprocess_text)\n",
    "\n",
    "# ÌÉÄÍ≤ü Ïª¨Îüº Î∂ÑÎ¶¨\n",
    "X = body_processed + \" [RULE] \" + rule_processed\n",
    "y = train_df[\"rule_violation\"]\n",
    "\n",
    "# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏóêÎèÑ ÎèôÏùºÌïú Ï†ÑÏ≤òÎ¶¨ Ï†ÅÏö©\n",
    "body_processed_test = test_df[\"body\"].apply(preprocess_text)\n",
    "rule_processed_test = test_df[\"rule\"].apply(preprocess_text)\n",
    "\n",
    "X_test = body_processed_test + \" [RULE] \" + rule_processed_test\n",
    "\n",
    "# Ï†ÑÏ≤òÎ¶¨Îêú ÏÉòÌîå Îç∞Ïù¥ÌÑ∞Î•º ÌôïÏù∏Ìï©ÎãàÎã§.\n",
    "print(f\"Processed data sample: {X.iloc[0][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba6aa87-710a-4256-b51e-d00917a07bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c274c8e-71f1-44d2-9d93-0a15e80107d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       banks dont want you to know this click here to...\n",
      "1       sd stream [ eng link 1] [URL] [RULE] no advert...\n",
      "2       lol try appealing the ban and say you wont do ...\n",
      "3       she will come your home open her legs with and...\n",
      "4       code free tyrande [imgur][URL] for you and you...\n",
      "                              ...                        \n",
      "2024    please edit your post so it is readable these ...\n",
      "2025    yes and in a right to work state they can even...\n",
      "2026    hd streams eng hd[ watch herepc mobile ][URL] ...\n",
      "2027    no not when doing so obviously presents a safe...\n",
      "2028    ca is an at fault state so they will not be ab...\n",
      "Length: 2029, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f4a31-b7de-4510-bee8-1a260c4cc34b",
   "metadata": {},
   "source": [
    "## ÏÑ±Îä• ÌèâÍ∞Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7e9a541-4151-4746-97cf-ebd0558dd71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Î≤°ÌÑ∞ shape:\n",
      "  Train: (1623, 2000)\n",
      "  Test: (406, 2000)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF ÏãúÌñâ\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=2000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1,3),\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)\n",
    "\n",
    "print(f'TF-IDF Î≤°ÌÑ∞ shape:')\n",
    "print(f'  Train: {X_train_tfidf.shape}')\n",
    "print(f'  Test: {X_val_tfidf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "701aa16a-d55f-4116-9e01-6400fd6b92a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Train_accuracy: 0.848\n",
      "Val_accuracy: 0.751\n",
      "Val_f1_score: 0.767\n",
      "\n",
      "Model: LinearSVC\n",
      "Train_accuracy: 0.954\n",
      "Val_accuracy: 0.754\n",
      "Val_f1_score: 0.756\n",
      "\n",
      "Model: SGD-Log\n",
      "Train_accuracy: 0.942\n",
      "Val_accuracy: 0.754\n",
      "Val_f1_score: 0.760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "models_sklearn = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42, n_jobs=-1),\n",
    "    \"LinearSVC\": LinearSVC(class_weight=\"balanced\"),\n",
    "    \"SGD-Log\": SGDClassifier(loss=\"log_loss\", class_weight=\"balanced\", max_iter=2000, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "for name, sk_model in models_sklearn.items():\n",
    "    sk_model.fit(X_train_tfidf, y_train)\n",
    "    y_tr_pred = sk_model.predict(X_train_tfidf)\n",
    "    y_val_pred = sk_model.predict(X_val_tfidf)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_tr_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Train_accuracy: {train_accuracy:.3f}\")\n",
    "    print(f\"Val_accuracy: {test_accuracy:.3f}\")\n",
    "    print(f\"Val_f1_score: {test_f1:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528a951-d152-4bd4-a589-051ab99477b3",
   "metadata": {},
   "source": [
    "## ÌÜ†ÌÅ∞Ìôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56be20ea-2890-45a5-affa-a3c38c61c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model_name, X_train, y_train, X_val, y_val, epochs=1):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "        id2label={0:\"not_violation\", 1:\"violation\"},\n",
    "        label2id={\"not_violation\":0, \"violation\":1}\n",
    "    )\n",
    "\n",
    "    tok_tr = tokenizer(list(X_train), truncation=True, max_length=128)\n",
    "    tok_val = tokenizer(list(X_val), truncation=True, max_length=128)\n",
    "    \n",
    "    tok_tr[\"labels\"] = y_train.tolist()\n",
    "    tok_val[\"labels\"] = y_val.tolist()\n",
    "    \n",
    "    ds_tr = Dataset.from_dict(tok_tr)\n",
    "    ds_val = Dataset.from_dict(tok_val)\n",
    "\n",
    "    collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    def metrics(p):\n",
    "        logits, labels = p\n",
    "        probs = torch.softmax(torch.tensor(logits), dim=-1)[:,1].numpy()\n",
    "        preds = (probs >= 0.5).astype(int)\n",
    "        return {\n",
    "            \"accuracy\":  accuracy_score(labels, preds),\n",
    "            \"f1\":        f1_score(labels, preds),\n",
    "            \"roc_auc\":   roc_auc_score(labels, probs),\n",
    "            \"pr_auc\":    average_precision_score(labels, probs),\n",
    "        }\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f'{RESULTS_PATH}/{model_name.replace(\"/\", \"_\")}',\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=8, \n",
    "        per_device_eval_batch_size=16,\n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=3e-5,\n",
    "        eval_strategy='epoch', \n",
    "        save_strategy='epoch',   \n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1',\n",
    "        weight_decay=0.01,\n",
    "        fp16=False,\n",
    "        logging_steps=100,\n",
    "        seed=42,\n",
    "        use_cpu=True,\n",
    "        no_cuda=True,\n",
    "        report_to='none',\n",
    "        disable_tqdm=False,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=ds_tr,\n",
    "        eval_dataset=ds_val,  \n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=metrics\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    pred = trainer.predict(ds_val)\n",
    "    probs = torch.softmax(torch.tensor(pred.predictions), dim=-1)[:,1].numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    \n",
    "    return trainer, tokenizer, ds_val, probs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e98adc1-3647-4f90-8815-412a59ca9306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/training_args.py:1636: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ü§ó Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "/var/folders/xl/hqfx0jqd111gpm_w0lswvptw0000gn/T/ipykernel_65732/158284287.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='306' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [306/306 08:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Pr Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.637700</td>\n",
       "      <td>0.641915</td>\n",
       "      <td>0.662562</td>\n",
       "      <td>0.602899</td>\n",
       "      <td>0.782451</td>\n",
       "      <td>0.781030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.480400</td>\n",
       "      <td>0.448893</td>\n",
       "      <td>0.783251</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.874272</td>\n",
       "      <td>0.880055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>0.470026</td>\n",
       "      <td>0.790640</td>\n",
       "      <td>0.799054</td>\n",
       "      <td>0.874345</td>\n",
       "      <td>0.879423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/training_args.py:1636: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ü§ó Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "/var/folders/xl/hqfx0jqd111gpm_w0lswvptw0000gn/T/ipykernel_65732/158284287.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='205' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [205/306 10:03 < 05:00, 0.34 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Pr Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.566654</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.806408</td>\n",
       "      <td>0.809173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.523500</td>\n",
       "      <td>0.478174</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.801762</td>\n",
       "      <td>0.866238</td>\n",
       "      <td>0.870502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: I/O error: No space left on device (os error 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tf_model \u001b[38;5;129;01min\u001b[39;00m transformer_model_ids:\n\u001b[0;32m---> 10\u001b[0m     trainer, tokenizer, ds_val, probs, preds \u001b[38;5;241m=\u001b[39m finetune_model(\n\u001b[1;32m     11\u001b[0m     tf_model, X_train, y_train, X_val, y_val, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m     results[tf_model] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: f1_score(y_val, preds),\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_score(y_val, preds),\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m: roc_auc_score(y_val, preds)\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 63\u001b[0m, in \u001b[0;36mfinetune_model\u001b[0;34m(model_name, X_train, y_train, X_val, y_val, epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     33\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     disable_tqdm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     54\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     55\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mmetrics\n\u001b[1;32m     61\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     65\u001b[0m pred \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(ds_val)\n\u001b[1;32m     66\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(torch\u001b[38;5;241m.\u001b[39mtensor(pred\u001b[38;5;241m.\u001b[39mpredictions), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2326\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2327\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2328\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2329\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2330\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:2790\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_log_save_evaluate(\n\u001b[1;32m   2791\u001b[0m     tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate\n\u001b[1;32m   2792\u001b[0m )\n\u001b[1;32m   2794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2795\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2796\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:3228\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;241m=\u001b[39m is_new_best_metric\n\u001b[1;32m   3227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial)\n\u001b[1;32m   3229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:3325\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3323\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3324\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 3325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;129;01min\u001b[39;00m [SaveStrategy\u001b[38;5;241m.\u001b[39mSTEPS, SaveStrategy\u001b[38;5;241m.\u001b[39mEPOCH] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_global_step:\n\u001b[1;32m   3328\u001b[0m     \u001b[38;5;66;03m# Wait for everyone to get here so we are sure the model has been saved by process 0\u001b[39;00m\n\u001b[1;32m   3329\u001b[0m     \u001b[38;5;66;03m# before we check if the best_checkpoint_dir exists\u001b[39;00m\n\u001b[1;32m   3330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:4227\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   4224\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   4226\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 4227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save(output_dir)\n\u001b[1;32m   4229\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   4230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:4331\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   4329\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   4330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(\n\u001b[1;32m   4332\u001b[0m         output_dir, state_dict\u001b[38;5;241m=\u001b[39mstate_dict, safe_serialization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_safetensors\n\u001b[1;32m   4333\u001b[0m     )\n\u001b[1;32m   4335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4336\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:4173\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   4168\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m   4170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[1;32m   4171\u001b[0m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[1;32m   4172\u001b[0m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[0;32m-> 4173\u001b[0m     safe_save_file(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file), metadata\u001b[38;5;241m=\u001b[39mmetadata)\n\u001b[1;32m   4174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4175\u001b[0m     save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/safetensors/torch.py:352\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    322\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    323\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    324\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ):\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m     serialize_file(_flatten(tensors), filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "\u001b[0;31mSafetensorError\u001b[0m: Error while serializing: I/O error: No space left on device (os error 28)"
     ]
    }
   ],
   "source": [
    "transformer_model_ids = [\n",
    "    \"distilroberta-base\",\n",
    "    \"bert-base-uncased\",\n",
    "    \"distilbert-base-uncased\",\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for tf_model in transformer_model_ids:\n",
    "    trainer, tokenizer, ds_val, probs, preds = finetune_model(\n",
    "    tf_model, X_train, y_train, X_val, y_val, epochs=3\n",
    ")\n",
    "    results[tf_model] = {\n",
    "        'f1': f1_score(y_val, preds),\n",
    "        'accuracy': accuracy_score(y_val, preds),\n",
    "        'roc_auc': roc_auc_score(y_val, preds)\n",
    "    }\n",
    "    \n",
    "    print(f\"Model: {tf_model}\")\n",
    "    print(f\" - F1: {results[tf_model]['f1']:.4f}\")\n",
    "    print(f\" - Accuracy: {results[tf_model]['accuracy']:.4f}\")\n",
    "    print(f\" - ROC-AUC: {results[tf_model]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821f193-f077-4814-83dd-d863f5e4e169",
   "metadata": {},
   "source": [
    "## ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖã ÌôïÎ•† ÏòàÏ∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9e142-5957-442f-af34-afb85bdec8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c6242-ba5e-4e7a-a734-2a137bb8f5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e6ca7-2eee-4d74-9c50-de5d66b70855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60009356-a7ca-4cc3-9cb5-7aef6ada0674",
   "metadata": {},
   "source": [
    "## Ï†úÏ∂ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e931452-4f61-4013-b4d2-6a70910948c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
